{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39093599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['영등포구청역', '에', '있', '는', '맛집', '좀', '알려', '주', '세요', '.']\n",
      "['영등포구청역', '맛집']\n",
      "[('영등포구청역', 'NNP'), ('에', 'JKB'), ('있', 'VV'), ('는', 'ETM'), ('맛집', 'NNG'), ('좀', 'MAG'), ('알려', 'VV+EC'), ('주', 'VX'), ('세요', 'EP+EF'), ('.', 'SF')]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()\n",
    "print(mecab.morphs(u'영등포구청역에 있는 맛집 좀 알려주세요.'))\n",
    "print(mecab.nouns(u'영등포구청역에 있는 맛집 좀 알려주세요.'))\n",
    "print(mecab.pos(u'영등포구청역에 있는 맛집 좀 알려주세요.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10705ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import koreanize_matplotlib\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c10824e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('https://raw.githubusercontent.com/haram4th/ablearn/main/ratings_train.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfc6f29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65444242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6270596</td>\n",
       "      <td>굳 ㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9274899</td>\n",
       "      <td>GDNTOPCLASSINTHECLUB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8544678</td>\n",
       "      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6825595</td>\n",
       "      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6723715</td>\n",
       "      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                           document  label\n",
       "0  6270596                                                굳 ㅋ      1\n",
       "1  9274899                               GDNTOPCLASSINTHECLUB      0\n",
       "2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
       "3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
       "4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('./data/ratings_test.csv',sep='\\t')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5e5000f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    75173\n",
       "1    74827\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31f2cad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    25173\n",
       "0    24827\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6bacdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   id        150000 non-null  int64 \n",
      " 1   document  149995 non-null  object\n",
      " 2   label     150000 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20497add",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.dropna()\n",
    "test_df = test_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34ab2995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                       아 더빙.. 진짜 짜증나네요 목소리\n",
       "1                         흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n",
       "2                                         너무재밓었다그래서보는것을추천한다\n",
       "3                             교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\n",
       "4         사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...\n",
       "                                ...                        \n",
       "149995                                  인간이 문제지.. 소는 뭔죄인가..\n",
       "149996                                        평점이 너무 낮아서...\n",
       "149997                      이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?\n",
       "149998                          청춘 영화의 최고봉.방황과 우울했던 날들의 자화상\n",
       "149999                             한국 영화 최초로 수간하는 내용이 담긴 영화\n",
       "Name: document, Length: 149995, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['document']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f41970",
   "metadata": {},
   "source": [
    "## 정규표현식을 이용한 텍스트 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "457c0046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf2fdd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clean(x):\n",
    "    pattern = r'[가-힣0-9a-zA-Z]+'\n",
    "    matches = re.findall(pattern, x)\n",
    "    matches = ' '.join(matches)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53847e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['document'] = train_df['document'].apply(text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48979884",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['document'] = test_df['document'].apply(text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "62ba0a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df['document']\n",
    "y = train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f63bf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "610dc3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fed6280",
   "metadata": {},
   "source": [
    "## CountVectorizer()\n",
    "* document에 있는 문자를 숫자로 변환 / 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36d8b350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3af96f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer() # 토크나이저가 공백 기주으로 토큰화\n",
    "X_train = cv.fit_transform(X_train)\n",
    "X_valid = cv.transform(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206df502",
   "metadata": {},
   "source": [
    "### 독립변수가 문자로 되어 있는 데이터의 경우 MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5ee2e5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3fa0f718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82     23267\n",
      "           1       0.81      0.83      0.82     21732\n",
      "\n",
      "    accuracy                           0.82     44999\n",
      "   macro avg       0.82      0.82      0.82     44999\n",
      "weighted avg       0.82      0.82      0.82     44999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "pred = mnb.predict(X_valid)\n",
    "print(classification_report(pred, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559d0824",
   "metadata": {},
   "source": [
    "## test 데이터 불러와서 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c16b1ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df['document']\n",
    "y_test = test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b6afb007",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vec = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d2f0563b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82     25707\n",
      "           1       0.81      0.84      0.82     24290\n",
      "\n",
      "    accuracy                           0.82     49997\n",
      "   macro avg       0.82      0.82      0.82     49997\n",
      "weighted avg       0.82      0.82      0.82     49997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred = mnb.predict(X_test_vec)\n",
    "print(classification_report(test_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fe07fd",
   "metadata": {},
   "source": [
    "# KoNLPy의 토크나이저 Mecab을 이용해 형태소 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c6ecbe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a2d8dc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    tokens = mecab.morphs(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dd1cc3",
   "metadata": {},
   "source": [
    "## CountVectorizer\n",
    "* 모든 단어를 벡터화시켜줌\n",
    "## TfidVectorizer\n",
    "* 자주 등장하는 단어에 가중치"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3122b2a8",
   "metadata": {},
   "source": [
    "### 1) CountVectorizer: 단어 빈도(횟수) 기반 벡터화\n",
    "* 작동 방식: CountVectorizer는 각 문서에서 등장한 단어의 **횟수(빈도)**를 기준으로 벡터를 만듭니다. 단순히 각 문서에서 특정 단어가 몇 번 등장했는지를 세어 벡터화합니다.<br>\n",
    "* 특징:\n",
    "    1) 각 단어의 빈도가 높을수록 해당 단어의 중요성이 더 크다고 가정합니다.<br>\n",
    "    2) 빈도가 높다는 것만을 고려하기 때문에, 모든 문서에서 자주 등장하는 단어도 중요한 단어로 처리될 수 있습니다.<br>\n",
    "* 예시:<br>\n",
    "* 예를 들어, 두 개의 문서가 있다면:<br>\n",
    "* 문서 1: \"고양이가 나무 위에 있다.\"<br>\n",
    "* 문서 2: \"나무 아래에 고양이가 있다.\"<br>\n",
    "* 이 두 문서를 CountVectorizer로 변환하면 단어 빈도가 포함된 벡터가 생성됩니다:<br>\n",
    "    * ['고양이': 2, '나무': 2, '위에': 1, '아래에': 1, '있다': 2]<br>\n",
    "### 2) TfidfVectorizer: TF-IDF (Term Frequency-Inverse Document Frequency) 기반 벡터화\n",
    "* 작동 방식: TfidfVectorizer는 단어의 빈도뿐만 아니라, 단어의 중요도를 계산합니다. 여기서는 TF-IDF 값을 사용하여 문서 간 차별성을 강조합니다.<br>\n",
    "* TF (Term Frequency): 단어가 문서에서 얼마나 자주 등장했는지를 나타냅니다.<br>\n",
    "* IDF (Inverse Document Frequency): 단어가 다른 문서에 얼마나 자주 등장하지 않았는지를 나타냅니다. 자주 등장하지 않는 단어는 더 중요한 단어로 간주합니다.<br>\n",
    "* 특징:<br>\n",
    "    1) TF-IDF는 문서 전체에서 자주 등장하는 흔한 단어들(예: \"그리고\", \"이다\" 등)의 중요도를 낮추고, 문서에서만 중요한 단어들의 중요도를 높입니다.<br>\n",
    "    2) 단순히 빈도가 높은 단어보다 특정 문서에서 더 특징적인 단어에 더 높은 가중치를 부여합니다.<br>\n",
    "* 예시:<br>\n",
    "* 위의 문서 1과 문서 2에 대해 TfidfVectorizer로 변환하면, 공통 단어들(예: \"있다\", \"고양이\")의 중요도는 낮아지고, 차별적인 단어(예: \"위에\", \"아래에\")의 중요도는 상대적으로 높아집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "78cc1e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# countervectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a79350cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = ['고양이가 나무 위에 있다.', '나무 아래에 고양이가 있다.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "84557402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['고양이가' '나무' '아래에' '위에' '있다']\n",
      "[[1 1 0 1 1]\n",
      " [1 1 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "c_vec = CountVectorizer()\n",
    "X = c_vec.fit_transform(doc)\n",
    "print(c_vec.get_feature_names_out()) # 벡터화된 단어 목록\n",
    "print(X.toarray()) # 단어 빈도 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3e4c17ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidvectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ae4f0963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['고양이가' '나무' '아래에' '위에' '있다']\n",
      "[[0.44832087 0.44832087 0.         0.63009934 0.44832087]\n",
      " [0.44832087 0.44832087 0.63009934 0.         0.44832087]]\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "X2 = tfidf.fit_transform(doc)\n",
    "print(tfidf.get_feature_names_out()) # 벡터화된 단어 목록\n",
    "print(X2.toarray()) # 단어 빈도 벡터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73229205",
   "metadata": {},
   "source": [
    "### CountVectorizer와 TfidfVectorizer 비교\n",
    "\n",
    "| **특성**             | **CountVectorizer**                                     | **TfidfVectorizer**                                               |\n",
    "|----------------------|--------------------------------------------------------|-------------------------------------------------------------------|\n",
    "| **기반**             | 단어의 단순 빈도                                        | 단어 빈도 + 문서 내에서의 상대적 중요도(TF-IDF)                     |\n",
    "| **단어 빈도 계산**    | 문서에서 등장한 단어의 단순한 등장 횟수를 셈            | 단어의 등장 횟수(TF)와 해당 단어가 문서들에서 얼마나 자주 등장하지 않았는지를 함께 고려(IDF) |\n",
    "| **빈번한 단어 처리**  | 문서에서 자주 등장하는 단어일수록 높은 가중치를 부여    | 문서에서 흔한 단어는 가중치를 낮추고, 드문 단어는 높은 가중치를 부여   |\n",
    "| **주요 용도**        | 단순한 단어 빈도 기반 분석이 필요할 때 사용             | 문서 간 차별적인 단어를 구별할 때 유용                                |\n",
    "| **계산 비용**         | 상대적으로 적음                                         | 상대적으로 더 복잡하고 계산 비용이 높음                                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a62b13",
   "metadata": {},
   "source": [
    "* tokenizer : 형태소를 분석해서 단어를 나누어 주는 역할, 기본은 공백 기준으로 나눔\n",
    "    * 한국어는 조사가 있기 때문에 공백이 아닌 형태소 분석을 통해서 나눠야함\n",
    "    * konlpy의 형태소 분석기를 이용해서 형태소를 나누고 분석\n",
    "* ngram_range(1,2)\n",
    "    * 단어를 벡터화할 때 단어의 범위를 지정\n",
    "    * (1,2) → 1-gram, 2-gram\n",
    "    * \"이 영화는 정말 좋다\"\n",
    "    * 1-gram : ['이','영화는','정말','좋다']\n",
    "    * 2-gram : ['이 영화는','영화는 정말','정말 좋다']\n",
    "* min_df=3:\n",
    "    * 단어가 등장하는 최소 문서 수를 설정하는 파리미터\n",
    "* max_df=0.9:\n",
    "    * 단어가 전체 문서의 90% 이하에서 등장할 때만 벡터화에 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b6ca51db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_X_train, tf_X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8d667212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ceun2/miniforge3/envs/fintech/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#tokenizer를 konlpy의 mecab사용\n",
    "tfidf = TfidfVectorizer(tokenizer=text_clean, ngram_range=(1,2), min_df=4, max_df=0.9)\n",
    "tf_X_train = tfidf.fit_transform(tf_X_train)\n",
    "tf_X_valid = tfidf.transform(tf_X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "36d3f4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.85     23012\n",
      "           1       0.84      0.85      0.84     21987\n",
      "\n",
      "    accuracy                           0.84     44999\n",
      "   macro avg       0.84      0.84      0.84     44999\n",
      "weighted avg       0.84      0.84      0.84     44999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(tf_X_train, y_train)\n",
    "pred = mnb.predict(tf_X_valid)\n",
    "print(classification_report(pred, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "15264db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84     25590\n",
      "           1       0.83      0.85      0.84     24407\n",
      "\n",
      "    accuracy                           0.84     49997\n",
      "   macro avg       0.84      0.84      0.84     49997\n",
      "weighted avg       0.84      0.84      0.84     49997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf_X_test =tfidf.transform(X_test)\n",
    "test_pred = mnb.predict(tf_X_test)\n",
    "print(classification_report(test_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf053cb",
   "metadata": {},
   "source": [
    "## random_forest와 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "15208ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a801c9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83     23561\n",
      "           1       0.80      0.84      0.82     21438\n",
      "\n",
      "    accuracy                           0.83     44999\n",
      "   macro avg       0.83      0.83      0.83     44999\n",
      "weighted avg       0.83      0.83      0.83     44999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(random_state=42, n_jobs=2)\n",
    "rfc.fit(tf_X_train, y_train)\n",
    "pred = rfc.predict(tf_X_valid)\n",
    "print(classification_report(pred, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7efb392b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84     25590\n",
      "           1       0.83      0.85      0.84     24407\n",
      "\n",
      "    accuracy                           0.84     49997\n",
      "   macro avg       0.84      0.84      0.84     49997\n",
      "weighted avg       0.84      0.84      0.84     49997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred = mnb.predict(tf_X_test)\n",
    "print(classification_report(test_pred, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
